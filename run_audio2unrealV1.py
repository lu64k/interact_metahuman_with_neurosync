# %%
#===================================== llmæ¨¡ç»„ ======================================

from utils.utils import init_api_key, get_timestamp
from utils.llm.text_utils import *
from utils.llm.llm_send import load_history
from utils.stt_llm_tts import Run_LLM_To_Anim
from utils.stt.Ali_voicer_rc import *
audio_que=Run_LLM_To_Anim()

#====================================å¿…è¦çš„ä¾èµ–=======================================
import aiohttp.client_exceptions
from pathlib import Path
import dashscope
from dashscope.audio.asr import Recognition, RecognitionCallback, RecognitionResult
import numpy as np
import threading
import json
from threading import Thread
import pyaudio
import warnings
import time
from datetime import datetime
import queue
from queue import Queue
import asyncio
warnings.filterwarnings(
    "ignore", 
    message="Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work"
)

#=====================================è¯­éŸ³è¯†åˆ«========================================

#--------------------------------------å…¨å±€å˜é‡---------------------------------------
  
recognition = None
recording_thread = None
sample_rate = 16000
channels = 1
block_size = 3200
SILENT_TIMEOUT = 1
MAX_SENTENCE_DURATION = 5
current_task = None  # è·Ÿè¸ªå½“å‰ä»»åŠ¡
callback_rc = Callback_rc()  # å®ä¾‹åŒ–å›è°ƒå‡½æ•°
rc_queue = callback_rc.rc_queue

def init_recognition(env_name='DASHSCOPE_API_KEY', input_api_key="è¾“å…¥ä½ çš„api"):
    """åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«"""
    global recognition
    dashscope.api_key = init_api_key(env_name, input_api_key)
    recognition = Recognition(
        model='paraformer-realtime-v2',
        format='pcm',
        sample_rate=16000,
        heartbeat=True,
        callback=callback_rc
    )
    recognition.start()
    print("Recording started...")

async def process_rc_queue(llm_model,chatname):
    print("Start processing queue")
    global current_task
    while True:
        if rc_queue.empty():
            await asyncio.sleep(0.1)  # é™ä½CPUå ç”¨
            if rc_queue.qsize() == 0 and not callback_rc.stream:
                print("Queue clean, stopping")
                break
        try:
            prompt = rc_queue.get()
            print(f"æ–°çš„æ–‡æœ¬ç”Ÿæˆï¼š{prompt}")
            if prompt:
                stop_event = asyncio.Event()
                callback_rc.stop_llm_generate = False
                audio_que.stop=False
                current_task = await audio_que.start_queue_audio(prompt, llm_model, stop_event, chatname)
                current_task = None            
                prompt = None

        except Exception as e:
            print(f"Queue processing error: {e}")
        finally:
            rc_queue.task_done()

async def async_recording():
    """å¼‚æ­¥å½•éŸ³å¾ªç¯ï¼Œéé˜»å¡è¯»éŸ³é¢‘"""
    global recognition,current_task
    loop = asyncio.get_event_loop()
    try:
        while recognition and callback_rc.stream:
            try:
                # ç”¨run_in_executoréé˜»å¡è¯»éŸ³é¢‘
                data = await loop.run_in_executor(None, lambda: callback_rc.stream.read(3200, exception_on_overflow=False))
                #print("è¯»å–å½•éŸ³...")
                recognition.send_audio_frame(data)#çº¿ç¨‹å·²é€šï¼Œon_eventå·²æ”¶å–ç»“æœä¸”æˆåŠŸæ’é˜Ÿ
                #print("å·²å‘é€å½•éŸ³åˆ°è¯†åˆ«")

                if callback_rc.stop_llm_generate == True and not callback_rc.first_run :#çº¿ç¨‹å·²é€šï¼Œå¯ä»¥è¢«å³æ—¶æ‰“æ–­
                    audio_que.stop = True
                    print("è¯•å›¾åœæ­¢æ‰§è¡Œå‡½æ•°æ”¶å–æ–°å†…å®¹å¾ªç¯")
                    await asyncio.sleep(5)
                    audio_que.stop = False
                    current_task = None
                    callback_rc.stop_llm_generate = False
            except aiohttp.client_exceptions.ClientConnectionResetError:
                print("WebSocket connection reset, retrying...")
                recognition.stop()
                init_recognition()
                return "retry"
            except Exception as e:
                print(f"Async recording error: {e}")
                if recognition:
                    recognition.stop()
                return
            #print("å°å¾ªç¯ä¸­")
    except Exception as e:
        print(f"Async recording loop error: {e}")

def record_and_recognize(if_end: bool, llm_model, chatname):  # å½•éŸ³çº¿ç¨‹ï¼Œæ¨é€åˆ°é˜Ÿåˆ—
    global recognition, recording_thread, current_task
    max_retries = 3
    for attempt in range(max_retries):
        try:
            if not if_end:
                # æ¸…ç†æ—§çŠ¶æ€
                if recognition:
                    recognition.stop()
                    recognition = None
                if recording_thread:
                    recording_thread.join()
                callback_rc.final_texts.clear()
                callback_rc.new_input = None
                callback_rc.stop_llm_generate = False
                while not callback_rc.rc_queue.empty():
                    callback_rc.rc_queue.get()
                    callback_rc.rc_queue.task_done()
                # å¯åŠ¨æ–°çº¿ç¨‹
                stt_thread = Thread(target=asyncio.run, args=(process_rc_queue(llm_model, chatname),))
                stt_thread.daemon = True
                stt_thread.start()
                init_recognition()
                recording_thread = Thread(target=asyncio.run, args=(async_recording(),))
                recording_thread.daemon = True
                recording_thread.start()
                return "", [], "Recording started"
                
            else:
                if recognition:
                    recognition.stop()
                    recognition = None
                if recording_thread:
                    recording_thread.join()
                paragraph = ''.join(callback_rc.final_texts)
                callback_rc.final_texts.clear()
                print("Recognition stopped. Paragraph:", paragraph)
                if paragraph:
                    return paragraph, [], "Recording stopped"
                return "", [], "Stopped with no text"
        except aiohttp.client_exceptions.ClientConnectionResetError:
            print(f"Connection reset, retry {attempt + 1}/{max_retries}")
            if attempt == max_retries - 1:
                return "", [], f"Failed after {max_retries} retries"
            continue
        except Exception as e:
            print(f"Unexpected error: {e}")
            if attempt == max_retries - 1:
                return "", [], f"Failed after {max_retries}: {e}"
            continue


chat_list = {
    "defult" :"defult",
    "å‰ä»–æ•™å®¤": "guitar",
    "è¯­è¨€æ•™å®¤": "japanese",
    "èŒä¸šè§„åˆ’": "career",
    "xxxooo": "xxxooo",
    "é—²èŠ": "small_talk",  
}

#=================================== Gradio ========================================== 
# Gradio ç•Œé¢#

sys_prompt_path = r"E:\Unreal Projects\lipsync_neurosync\unrealversion\config_files\sys_prompt.txt"
system_prompt=load_text(sys_prompt_path)

async def auto_load_history(chatname, status, chatbot):
    while True:
        path, history = load_history(chatname)
        yield {"status": f"Auto-loaded history from {path}", "chatbot": history}
        await asyncio.sleep(60)  # æ¯60ç§’åŠ è½½ä¸€æ¬¡


import gradio as gr
with gr.Blocks() as demo:
    gr.Markdown("# è¯­éŸ³+LLM èŠå¤©æœºå™¨äºº")
    with gr.Row():
        with gr.Column(scale=1):
            record_btn = gr.Button("ğŸ™ï¸ å¼€å§‹å½•éŸ³")
            stop_btn = gr.Button("â¹ï¸ åœæ­¢å½•éŸ³")
        with gr.Column(scale=3):
            text_input = gr.Textbox(label="è¾“å…¥æˆ–å½•éŸ³ç»“æœ", placeholder="è¯´ç‚¹å•¥...")
            send_btn = gr.Button("ğŸš€ å‘é€")
            update_btn = gr.Button("æ›´æ–°å¯¹è¯å†å²")
    chats = gr.Dropdown(choices=list(chat_list.keys()), label="é€‰æ‹©å¯¹è¯", value=list(chat_list.keys())[0])
    chatbot = gr.Chatbot( type="messages", label="å¯¹è¯")
    status = gr. Textbox(label="unrealè¯·æ±‚æƒ…å†µ")
    with gr.Accordion("LLM è®¾ç½®", open=False):
        model = gr.Dropdown(choices=["grok-3", "gpt-4o-mini", "deepseek-chat"], label="æ¨¡å‹", value="grok-3")

    record_btn.click(
        record_and_recognize,
        inputs=[gr.State(False), model, chats],
        outputs=[text_input,chatbot,status]
    )
    stop_btn.click(
        record_and_recognize,
        inputs=[gr.State(True), model, chats],
        outputs=[text_input,chatbot,status]
    )

    '''    text_input.submit(
            audio_que.start_queue_audio,
            inputs=[text_input, model, chats],
            outputs=[text_input,chatbot,status]
        )'''

    chats.change(
        load_history,
        inputs=[chats],
        outputs=[status,chatbot]
    )
    update_btn.click(
        load_history,
        inputs=[chats],
        outputs=[status,chatbot]
    )
    demo.load(
        auto_load_history,
        inputs=[chats, status, chatbot],
        outputs=[status, chatbot],
        queue=True
    )
demo.launch(server_port=8999, debug=True)

    


