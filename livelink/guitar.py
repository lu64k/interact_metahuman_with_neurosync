import sounddevice as sd
import numpy as np
import queue
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

# ====== è‡ªåŠ¨æŸ¥æ‰¾â€œçº¿è·¯è¾“å…¥â€è®¾å¤‡ID ======
devices = sd.query_devices()
line_in_id = None
for idx, dev in enumerate(devices):
    # è¿™é‡Œä»¥ä¸­æ–‡â€œçº¿è·¯è¾“å…¥â€ä¸ºä¾‹ï¼Œè‹±æ–‡ç³»ç»Ÿå¯æ”¹æˆ "Line In"
    if "çº¿è·¯è¾“å…¥" in dev['name'] and dev['max_input_channels'] > 0:
        line_in_id = idx
        print(f"ğŸ” æ‰¾åˆ°çº¿è·¯è¾“å…¥: [ID:{idx}] {dev['name']}")
        break
if line_in_id is None:
    raise RuntimeError("âŒ æœªæ‰¾åˆ°â€œçº¿è·¯è¾“å…¥â€è®¾å¤‡ï¼Œè¯·æ£€æŸ¥è®¾å¤‡åˆ—è¡¨ã€‚")

# ====== é€‰è¾“å‡ºè®¾å¤‡ï¼ˆç”¨é»˜è®¤æ‰¬å£°å™¨ï¼‰ ======
# sd.default.device è¿”å› (input_id, output_id)
_, default_out = sd.default.device
print(f"ğŸ” é»˜è®¤è¾“å‡ºè®¾å¤‡: [ID:{default_out}] {devices[default_out]['name']}")

# ====== å‚æ•°é…ç½® ======
INPUT_ID    = line_in_id
OUTPUT_ID   = default_out
in_info     = sd.query_devices(INPUT_ID,  kind='input')
out_info    = sd.query_devices(OUTPUT_ID, kind='output')
SAMPLE_RATE = int(in_info['default_samplerate'])
BUFFER_SIZE = 128

print(f"â–¶ï¸ é‡‡æ ·ç‡: {SAMPLE_RATE} Hz, è¾“å…¥é€šé“: {in_info['max_input_channels']}, è¾“å‡ºé€šé“: {out_info['max_output_channels']}")

# ====== é˜Ÿåˆ— & å›è°ƒ ======
audio_q = queue.Queue()

def input_cb(indata, frames, t, status):
    if status: print("âš ï¸ è¾“å…¥è­¦å‘Š:", status)
    audio_q.put(indata.copy())

def output_cb(outdata, frames, t, status):
    if status: print("âš ï¸ è¾“å‡ºè­¦å‘Š:", status)
    try:
        data = audio_q.get_nowait()
    except queue.Empty:
        outdata.fill(0)
    else:
        outdata[:] = data

# ====== ï¼ˆå¯é€‰ï¼‰æ³¢å½¢å¯è§†åŒ– ======
def visualize():
    fig, ax = plt.subplots()
    duration = 3.0
    total = int(duration * SAMPLE_RATE)
    times = np.linspace(0, duration, total)
    buf = np.zeros(total, dtype=np.float32)
    line, = ax.plot(times, buf)
    ax.set_xlim(0, duration); ax.set_ylim(-1,1)
    ax.set_xlabel("æ—¶é—´ (s)"); ax.set_ylabel("æŒ¯å¹…"); ax.grid(True)

    def update(_):
        nonlocal buf
        while not audio_q.empty():
            stereo = audio_q.get_nowait()
            mono = stereo[:, 0]  # å–å·¦å£°é“æ˜¾ç¤º
            buf = np.roll(buf, -len(mono))
            buf[-len(mono):] = mono
        line.set_ydata(buf)
        return line,

    return fig, FuncAnimation(fig, update, interval=30, blit=True)

# ====== å¯åŠ¨åŒæµç›‘å¬ ======
def start_linein_monitor():
    in_strm = sd.InputStream(
        device=INPUT_ID,
        channels=in_info['max_input_channels'],
        samplerate=SAMPLE_RATE,
        blocksize=BUFFER_SIZE,
        callback=input_cb
    )
    out_strm = sd.OutputStream(
        device=OUTPUT_ID,
        channels=out_info['max_output_channels'],
        samplerate=SAMPLE_RATE,
        blocksize=BUFFER_SIZE,
        latency='low',
        callback=output_cb
    )

    print(f"ğŸš€ ç›‘å¬çº¿è·¯è¾“å…¥â†’æ‰¬å£°å™¨  (in={INPUT_ID}, out={OUTPUT_ID})")
    with in_strm, out_strm:
        # å¦‚æœæƒ³çœ‹æ³¢å½¢å°±æ‰“å¼€ä¸‹é¢ä¸¤è¡Œï¼Œå¦åˆ™åˆ æ‰ visualize() ç›¸å…³
        fig, ani = visualize()
        plt.show()
        # å¦‚æœä¸çœ‹æ³¢å½¢ï¼Œå¯ä»¥æ”¹æˆï¼š
        # threading.Event().wait()  # ä¸€ç›´è¿è¡Œï¼Œç›´åˆ° Ctrl+C

if __name__ == "__main__":
    start_linein_monitor()
