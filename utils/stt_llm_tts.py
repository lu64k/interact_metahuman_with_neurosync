
from utils.files.file_utils import save_generated_data, initialize_directories
from livelink.connect.livelink_init import create_socket_connection, initialize_py_face
from livelink.animations.default_animation import default_animation_loop, stop_default_animation
from utils.tts.tts_tools import *   #å¯¼å…¥tts
from utils.llm.llm_send import LLMChat
from utils_local_api.generate_face_shapes import generate_facial_data_from_bytes
from utils_local_api.model.model import load_model
from utils_local_api.config import config
from utils.generated_runners import run_audio_animation
import queue
import random
import torch
import time
import numpy as np
from threading import Thread
import threading
import asyncio

def parse_blendshapes_from_json(json_response):
    blendshapes = json_response.get("blendshapes", [])
    facial_data = []

    for frame in blendshapes:
        frame_data = [float(value) for value in frame]
        facial_data.append(frame_data)

    return facial_data

llm_chat = LLMChat()

class Run_LLM_To_Anim():
    def __init__(self):
    # å…¨å±€åŠ¨ç”»åˆæˆèµ„æºåˆå§‹åŒ–
        self.ENABLE_EMOTE_CALLS = False
        self.model_path = 'utils_local_api/model/model.pth'
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.blendshape_model = load_model(self.model_path, config, self.device)
        self.start_default_animation = False  #é»˜è®¤è„¸éƒ¨å¾…æœºåŠ¨ç”»å¼€å…³ï¼Œå¦‚æœè™šå¹»æ²¡æœ‰åšè„¸éƒ¨å¾…æœºåŠ¨ç”»å°±æ”¹æˆTrueï¼Œä¸ç„¶ä¼šå¯¼è‡´åŠ¨ç”»é‡å       
        self.seed = random.seed
        self.tts_queue= queue.Queue()        
        self.py_face, self.socket_connection, self.default_animation_thread = self.initialize_resources(self.start_default_animation)
        self.stop = False

    def initialize_resources(self, start_default_animation=True):
        initialize_directories()
        py_face = initialize_py_face()
        socket_connection = create_socket_connection()
        
        default_animation_thread = None
        if start_default_animation:
            default_animation_thread = Thread(target=default_animation_loop, args=(self.py_face,))
            default_animation_thread.start()

        return py_face, socket_connection, default_animation_thread

    def audio_to_blendshapes_route(self, audio_bytes):
        generated_facial_data = generate_facial_data_from_bytes(audio_bytes, self.blendshape_model, self.device, config)
        generated_facial_data_list = generated_facial_data.tolist() if isinstance(generated_facial_data, np.ndarray) else generated_facial_data
        return  generated_facial_data_list


    def process_audio_queue(self):
        while True:
            if self.stop:
                while not self.tts_queue.empty():
                    self.tts_queue.get()
                    self.tts_queue.task_done()
                print("TTS queue cleared due to stop signal")
                break
            if self.tts_queue.empty():
                time.sleep(0.1)  # åŒæ­¥ç­‰å¾…ï¼Œé¿å…ç©ºè½¬CPU
                if self.tts_queue.qsize() == 0 and llm_chat.on_streaming==False:  # ç¡®è®¤TTSæµç»“æŸä¸”é˜Ÿåˆ—ç©º
                    print("TTSå®Œäº‹ï¼Œé˜Ÿåˆ—ä¹Ÿç©ºï¼Œæ’¤äº†ï¼")
                    break
            #print("å¼€å§‹æéŸ³é¢‘ï¼")
            audio_wav = self.tts_queue.get()
            start_time = time.time()
            print(f"é˜Ÿåˆ—è¿˜å‰©: {self.tts_queue.qsize()}æ®µéŸ³é¢‘")
            with app.app_context():
                if audio_wav:
                    try:
                        # é¢éƒ¨æ•°æ®å¤„ç†
                        facial_data_raw = self.audio_to_blendshapes_route(audio_wav)
                        facial_data = parse_blendshapes_from_json({'blendshapes': facial_data_raw})
                        #print(f"é¢éƒ¨æ•°æ®å¸§æ•°: {len(facial_data)}")
                        if facial_data:
                            # è·‘åŠ¨ç”»
                            run_audio_animation(audio_wav, facial_data, self.py_face, self.socket_connection, self.default_animation_thread)
                            #print("åŠ¨ç”»è·‘èµ·æ¥å•¦ï¼")
                        else:
                            print("é¢éƒ¨æ•°æ®ç©ºäº†ï¼Œè·³è¿‡å§")
                    except Exception as e:
                        print(f"ç¿»è½¦äº†: {e}")
                    finally:
                        self.tts_queue.task_done()
                        #print(f"è¿™æ®µéŸ³é¢‘æå®šï¼Œè€—æ—¶: {time.time() - start_time:.3f}ç§’")
                else:
                    if self.tts_queue.qsize() == 0:
                        self.tts_queue.task_done()

    async def process_llm_to_tts(self, prompt, llm_model,stop_event: asyncio.Event, chatname:str):
        try:
            result = []
            #if stop_event.is_set():
                #self.tts_queue.task_done()
            async for text in llm_chat.process_streaming_content(prompt,llm_model,stop_event, chatname):
                if text:
                    #print(f"process_llm_to_tts received {text}")
                    if self.stop is True:
                        llm_chat.is_streaming_done()
                        await asyncio.sleep(0.2)
                        print("ttsé˜Ÿåˆ—è¢«æ‰“æ–­æ¸…ç©º")
                        return
                    audio = await call_TTS(text)
                if audio:
                    #print(f"ğŸ”Š äºŒè¿›åˆ¶éŸ³é¢‘é•¿åº¦ï¼š{len(audio)}")
                    self.tts_queue.put(audio)
                    result.append(text)
                else:
                    print("âš ï¸ call_TTS è¿”å›ç©ºéŸ³é¢‘")

            self.tts_queue.put(None)
            return "".join(result)

        except Exception as e:
            print(f"âŒ Process LLM to TTS error: {e}")
            # ç¡®ä¿ä¸Šå±‚çŸ¥é“ç»“æŸ
            try:
                self.tts_queue.put(None)
            except:
                pass
            return ""
            
    async def start_queue_audio(self, prompt, llm_model, stop_event: asyncio.Event, chatname:str):
        try:
            from threading import Thread
            tts_thread = Thread(target=self.process_audio_queue)  # åŒæ­¥çº¿ç¨‹è·‘é˜Ÿåˆ—
            tts_thread.start()
            response = await self.process_llm_to_tts(prompt, llm_model, stop_event, chatname)  # å¼‚æ­¥TTS
            tts_thread.join()  # ç­‰å¾…çº¿ç¨‹
            print ("æ‰€ä»¥é˜Ÿåˆ—å·²ç»å®Œæˆ")
            return response
        except Exception as e:
            print(f"Start queue audio error: {e}")
            return ""

